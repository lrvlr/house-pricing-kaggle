{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import category_encoders as ce\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "#Scaling data\n",
    "from sklearn.preprocessing import RobustScaler, Normalizer\n",
    "\n",
    "#Regressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_params() function looks at the init arguments to figure out what the class parameters are and then assumes that they're the same as the internal variable names. https://stackoverflow.com/questions/61394346/why-is-my-sklearn-custom-transformer-not-saving-an-attribute-when-used-in-a-colu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBoostCustom(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Given a list of categorical variables applies CatBoostEncoder on them\n",
    "    in a pipeline. \n",
    "    '''\n",
    "\n",
    "    def __init__(self, cat):\n",
    "        self.cat = cat  \n",
    "        self.cbe = ce.CatBoostEncoder(cols=cat, handle_unknown='value')\n",
    "        \n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X[self.cat] = self.cbe.transform(X[self.cat])\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.cbe.fit(X[self.cat], y)\n",
    "        return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotCustom(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Given a list of variables applies OneHotEncoder on them\n",
    "    in a pipeline. \n",
    "    '''\n",
    "\n",
    "    def __init__(self, cat):\n",
    "        self.cat = cat  \n",
    "        self.ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        \n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X=pd.concat([X.drop(columns=self.cat), pd.DataFrame(self.ohe.transform(X[self.cat]))], axis=1)\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.ohe.fit(X[self.cat], y)\n",
    "#         print(self.ohe.get_feature_names())\n",
    "        return self \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImputer(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Simple Imputer that conserves column names. To be able to impute missing values before encoding and creating bivariates\n",
    "    '''\n",
    "\n",
    "    def __init__(self, strategy='mean', fill_value=-1):\n",
    "        self.strategy = strategy\n",
    "        self.fill_value = fill_value\n",
    "        self.imp = SimpleImputer(strategy=self.strategy, fill_value=self.fill_value)\n",
    "        \n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        colnames = X.columns        \n",
    "        X = pd.DataFrame(self.imp.transform(X))\n",
    "        X.columns = colnames\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.imp.fit(X, y)\n",
    "        return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Robust scaler that conserves column names. To be able to scale before encoding and creating bivariates\n",
    "    '''\n",
    "\n",
    "    def __init__(self, rng):\n",
    "        self.rng = rng\n",
    "        self.scaler = RobustScaler(quantile_range=self.rng)\n",
    "        \n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        colnames = X.columns        \n",
    "        X = pd.DataFrame(self.scaler.transform(X))\n",
    "        X.columns = colnames\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X, y)\n",
    "        return self \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBivariates(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Given a dictionary of bivariate feature names as keys, and tuples of two (string) feature names as values,\n",
    "    creates the bivariate feature as a result of concatenating the two feature strings.\n",
    "    By default it drops the original categorical features\n",
    "    '''\n",
    "    def __init__(self, features={}, drop=True, dismiss=[]):\n",
    "        self.features = features\n",
    "        self.drop = drop\n",
    "        self.dismiss = dismiss\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        dropall= True if (self.drop & (len(self.dismiss)==0)) else False\n",
    "        \n",
    "        for name, fts in self.features.items():\n",
    "            X[name] = X[fts[0]].astype(str) + '-' + X[fts[1]].astype(str)\n",
    "            if dropall:\n",
    "                self.dismiss.extend([fts[0], fts[1]])\n",
    "        X.drop(columns=self.dismiss, inplace=True)\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def getDismissed(self):\n",
    "        return self.dismiss\n",
    "    \n",
    "    def getVars(self):\n",
    "        return self.features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumBivariates(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Creates bivariates named as the feature dictionary keys, according to method:\n",
    "    mulBiv:\n",
    "    dictionary values should be two features of the dataFrame, returns the result of multiplying them\n",
    "    \n",
    "    sumBiv:\n",
    "    dictionary values should be a list of features, returns the result of adding them\n",
    "    \n",
    "    difBiv:\n",
    "    dictionary values should be two features of the dataFrame, returns the difference.\n",
    "    \n",
    "    boolBiv:\n",
    "    dictionary values should be a features and a threshold, 1 if feature value is higher than threshold, 0 otherwise.\n",
    "    \n",
    "    binsBiv:\n",
    "    dictionary values should be a feature, a list of binedges, a list of labels, applies pd.cut with those parameters.\n",
    "    \n",
    "    \n",
    "    By default it does not drop features. If drop is true and dismiss is empty, drops all features used in mulBiv, or difBiv methods.\n",
    "    There would be an error if trying to use this with other methods.\n",
    "    \n",
    "    If dismiss contains a list, drops all features in dismiss.\n",
    "    \n",
    "    If asDummies is True, returns dummies of the created bivariates.\n",
    "    '''\n",
    "    def __init__(self, features={}, drop=False, dismiss=[], method='mulBiv', asDummies=False):\n",
    "        self.features = features\n",
    "        self.drop = drop\n",
    "        self.dismiss = dismiss\n",
    "        self.method = method # getattr(self, method)\n",
    "        self.asDummies = asDummies\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        dropall= True if (self.drop & (len(self.dismiss)==0)) else False\n",
    "       \n",
    "        for name, fts in self.features.items():\n",
    "            X[name] = getattr(self, self.method)(X, fts) \n",
    "            if self.asDummies:\n",
    "                X = pd.get_dummies(X, columns=[name], drop_first=False)\n",
    "            if dropall:\n",
    "#                 X.drop(columns=[fts[0], fts[1]], inplace=True)\n",
    "                self.dismiss.extend([fts[0], fts[1]])\n",
    "        X.drop(columns=self.dismiss, inplace=True)\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def getDismissed(self):\n",
    "        return self.dismissed \n",
    "    \n",
    "    def getVars(self):\n",
    "        return self.features\n",
    "    \n",
    "    def mulBiv(self, X, fts):\n",
    "        return X[fts[0]] * X[fts[1]]\n",
    "\n",
    "    def boolBiv(self, X, fts):\n",
    "        return (X[fts[0]] > fts[1]).astype(int)\n",
    "    \n",
    "    def sumBiv(self, X, fts):\n",
    "        return X[fts].sum(axis=1)\n",
    "    \n",
    "    def difBiv(self, X, fts):\n",
    "        return X[fts[0]] - X[fts[1]]\n",
    "    \n",
    "    def binsBiv(self, X, fts):\n",
    "        return pd.cut(X[fts[0]], bins=fts[1], labels=fts[2]).astype(int)    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumBivariatesBool(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    This was included as a method in NumBivariates, I keep this for older versions\n",
    "    Given a dictionary of bivariate feature names as keys, and tuples of one feature and a lower limit,\n",
    "    returns a boolean variable (cast as int) as the result of dividing the feature values by the limit.\n",
    "    Ex: ('Num', 15) returns 1 for every value in num strictly higher than 15, 0 otherwise.\n",
    "    By default it does not drop the original features\n",
    "    '''\n",
    "    def __init__(self, features={}, drop=False, dismiss=[]):\n",
    "        self.features = features\n",
    "        self.drop = drop\n",
    "        self.dismiss = dismiss\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        dropall= True if (self.drop & (len(self.dismiss)==0)) else False\n",
    "\n",
    "        for name, fts in self.features.items():\n",
    "            X[name] = (X[fts[0]] > fts[1]).astype(int)\n",
    "            #X = pd.concat([X,new], axis=1)\n",
    "            if dropall:\n",
    "#                 X.drop(columns=[fts[0]], inplace=True)\n",
    "                self.dismiss.append(fts[0])\n",
    "        X.drop(columns=self.dismiss, inplace=True)\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def getDismissed(self):\n",
    "        #\"ALO\"\n",
    "        return self.dismiss \n",
    "    \n",
    "    def getVars(self):\n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRtTransformer(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Applies log transform to features in log list\n",
    "    cube root transform to features in cbrt list\n",
    "    and square root for features in sqrt\n",
    "    '''\n",
    "#     def __init__(self):\n",
    "    def __init__(self, log=[], cbrt=[], sqrt=[]):\n",
    "        self.log = log\n",
    "        self.cbrt = cbrt\n",
    "        self.sqrt = sqrt\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        for ftl in self.log:\n",
    "            X[ftl] = np.log(X[ftl])\n",
    "        for ftc in self.cbrt:\n",
    "            X[ftc] = np.cbrt(X[ftc])\n",
    "        for fts in self.sqrt:\n",
    "            X[fts] = np.sqrt(X[fts])\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def getVars(self):\n",
    "        return self.log, self.cbrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
